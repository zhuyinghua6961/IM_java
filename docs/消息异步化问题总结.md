# 消息异步化改造问题总结

## 1. 背景

消息服务引入 **Kafka + Redis 异步持久化**：

- 发送消息时：
  - 先写 Redis（缓存消息详情 / 会话列表）。
  - 再通过 Kafka 异步写入 MySQL。
- 单聊原本已经采用异步链路，本轮改造中又让 **群聊也走相同的异步链路**。
- 同时支持 **消息撤回**：
  - 撤回接口根据 `messageId` 在 Redis / MySQL 查询消息；
  - 根据持久化状态（PENDING / PERSISTED）决定如何处理：仅在 Redis 打撤回标记，还是发送 Kafka 撤回事件更新数据库。

在改造和联调过程中，主要遇到了两类问题：

1. Kafka 环境 / Topic 配置问题。
2. 雪花 ID 在前端被 JS Number 精度截断，导致撤回 404「消息不存在」。

---

## 2. 问题一：Kafka 环境 & Topic 分区不一致

### 2.1 现象

后端日志中出现大量错误：

```text
TimeoutException: Topic im-message-private not present in metadata after 10000 ms.
```

并伴随类似信息：

```text
Error while sending message to topic im-message-private with key ...
```

说明 Producer 无法正常获取 `im-message-private` 的元数据。

### 2.2 排查过程

1. **检查 Kafka CLI 是否可用**

   ```bash
   kafka-topics.sh --bootstrap-server localhost:9092 --list
   ```

   初次执行报 `command not found`，说明：

   - Kafka CLI 没有在 PATH 中；
   - 或者 Kafka 没有正确安装。

2. **确认通过 Homebrew 安装了 Kafka**

   ```bash
   brew list | grep kafka      # 输出：kafka
   /opt/homebrew/opt/kafka/bin/kafka-topics --version  # 输出：4.0.0
   ```

   说明本机 Kafka 安装正常，CLI 位置为 `/opt/homebrew/opt/kafka/bin/…`。

3. **查看 topic 配置**

   ```bash
   /opt/homebrew/opt/kafka/bin/kafka-topics \
     --describe \
     --topic im-message-private \
     --bootstrap-server localhost:9092
   ```

   初始输出：

   ```text
   Topic: im-message-private  PartitionCount: 1  ReplicationFactor: 1
   ```

   即 **topic 只有 1 个分区**。

4. **对比应用配置**

   `application.yml` 中：

   ```yaml
   im:
     message:
       kafka-topic: im-message-private
       kafka-partitions: 10
   ```

   发送 Kafka 的代码：

   ```java
   String conversationId = message.getChatType() == 1 ?
       generateConversationId(message.getFromUserId(), message.getToId()) :
       String.valueOf(message.getToId());

   int partition = Math.abs(conversationId.hashCode()) % kafkaPartitions; // 10

   kafkaTemplate.send(kafkaTopic, partition, conversationId, json);
   ```

   - 代码会把消息发到 **0~9** 任意一个分区；
   - 但 topic 实际只有分区 0，1~9 分区并不存在。

### 2.3 根因

- Kafka topic `im-message-private` 已存在，但 **实际分区数 = 1**。
- 应用配置 `im.message.kafka-partitions = 10`，与实际不一致。
- Producer 按 10 个分区取模，导致部分消息尝试发往不存在的分区，从而触发 metadata / timeout 异常。

### 2.4 解决方案

1. **把 topic 分区数与配置对齐**

   ```bash
   /opt/homebrew/opt/kafka/bin/kafka-topics \
     --alter \
     --topic im-message-private \
     --partitions 10 \
     --bootstrap-server localhost:9092
   ```

   再次 `describe`，确认：

   ```text
   PartitionCount: 10
   Partition: 0..9 都存在
   ```

2. **保留应用配置**

   ```yaml
   im.message.kafka-partitions: 10
   ```

   与实际 `PartitionCount = 10` 一致。

3. **确保 Kafka Broker 在 `localhost:9092` 正常启动**。

修复之后：

- 异步持久化链路恢复正常：
  - `消息已缓存并发送到Kafka: messageId=..., partition=...`
  - `开始持久化消息: messageId=...`
  - `消息持久化成功: ...`
- 不再出现 `Topic not present in metadata` 和超时异常。

---

## 3. 问题二：雪花 Long ID 精度丢失导致撤回 404

### 3.1 现象

单聊 / 群聊消息：

- 发送成功，Kafka 持久化成功；
- 但在前端点击「撤回」时，接口返回：

```json
{
  "code": 404,
  "message": "消息不存在",
  ...
}
```

后端日志：

```text
撤回消息: userId=5, messageId=518039478749761540
从Redis查询消息详情: key=msg:detail:518039478749761540
Redis中没有消息详情: messageId=518039478749761540
从MySQL查询消息: messageId=518039478749761540, result=未找到
消息不存在（Redis和MySQL都未找到），messageId: 518039478749761540
```

但同一条消息在发送时的日志为：

```text
消息已缓存并发送到Kafka: messageId=518039478749761536
消息发送成功，messageId: 518039478749761536
消息持久化成功: 518039478749761536
```

对比可以发现：

- 发送 / 持久化使用的 ID 是：**518039478749761536**；
- 撤回请求中带的 ID 是：**518039478749761540**；
- 两者只差 4，导致 Redis / MySQL 中查不到这条“错误 ID”的消息。

### 3.2 根因

- 后端使用 **雪花算法** 生成 64 位 Long 类型 messageId，例如 `5180...7536`；
- 该数值远大于 JS 能精确表示的最大安全整数 `2^53 - 1`；
- 后端通过 JSON 返回时，`messageId` / `id` 字段是数字类型：
  - `/message/history` 接口返回的 `msg.id`；
  - WebSocket 推送中的 `messageId`；
  - ACK 消息中的 `messageId`；
- 浏览器端 JS 使用 `Number`（双精度浮点）存储这些大整数，发生舍入：

  ```text
  518039478749761536  →  518039478749761540
  ```

- 前端撤回时：

  ```js
  await request.post('/message/recall', { messageId: message.id })
  ```

  此时的 `message.id` 已经是被 JS 舍入过的「错误 ID」，后端自然在 Redis / MySQL 里查不到，于是抛出 `404 消息不存在`。

### 3.3 解决方案

**核心思路：前后端对所有 messageId / id 全程使用字符串，不使用 JS Number 存储大整数。**

#### 3.3.1 后端改动

1. **实体 `Message.id` 序列化为字符串**

   ```java
   @Data
   public class Message {
       @JsonSerialize(using = ToStringSerializer.class)
       private Long id;
       ...
   }
   ```

   - 使 `/message/history` 返回的 `id` 字段变为字符串，如：`"518039478749761536"`。

2. **WebSocket ACK / 推送消息中的 `messageId` 改为字符串**

   `WebSocketMessageHandler`：

   ```java
   // ACK
   ack.put("messageId", String.valueOf(messageId));

   // 单聊推送 / 群聊推送
   message.put("messageId", String.valueOf(messageId));
   ```

3. **通知 DTO 中的 ID 统一为字符串**

   `MessageNotificationDTO`：

   ```java
   private String messageId;
   private List<String> messageIds;
   ```

   构造时：

   ```java
   .messageId(String.valueOf(messageId));

   .messageIds(messageIds.stream()
       .map(String::valueOf)
       .collect(Collectors.toList()));
   ```

#### 3.3.2 前端改动

1. **WebSocket 收到新消息时，强制把 `messageId` 转为字符串**

   `websocketClient.js`：

   ```js
   const messageObj = {
     id: String(data.messageId),
     fromUserId: data.fromUserId,
     content: data.content,
     ...
   }
   ```

2. **历史消息加载时，对 `msg.id` 做字符串转换**

   `Chat.vue / loadHistoryMessages`：

   ```js
   return {
     id: String(msg.id),
     fromUserId: msg.fromUserId,
     ...
   }
   ```

3. **ACK 回调中，使用字符串形式更新本地消息 ID**

   ```js
   if (msgIndex !== -1) {
     const oldId = messages.value[msgIndex].id
     messages.value[msgIndex].id = String(ackData.messageId)
     messages.value[msgIndex].status = 1
   }
   ```

4. **通知处理逻辑中统一用字符串比对 `messageId`**

   ```js
   // NEW_MESSAGE
   id: String(data.messageId)

   // MESSAGE_RECALLED
   const targetId = String(data.messageId)
   const message = messages.value.find(m => String(m.id) === targetId)
   ```

5. **撤回接口仍然可以直接传 `message.id`**

   ```js
   await request.post('/message/recall', { messageId: message.id })
   ```

   - 现在的 `message.id` 已经是字符串；
   - Spring MVC 会自动将 JSON 中的字符串转换为 Long 参数值，无需额外改造。

### 3.4 修复效果

- 发送、ACK、撤回日志中的 `messageId` 完全一致，不再出现尾数相差几位的情况；
- 撤回接口不再返回 `404 消息不存在`，Redis / MySQL 均能正确查到对应消息；
- 单聊与群聊的撤回路径统一走 Kafka + Redis 的异步机制，行为一致、可观测性更好。

---

## 4. 经验与建议

1. **Kafka 配置与实际 Topic 必须强一致**

   - `im.message.kafka-topic` 必须指向真实存在的 topic；
   - `im.message.kafka-partitions` 必须与该 topic 的 `PartitionCount` 一致；
   - 环境层面的问题（topic 未创建、broker 未启动、分区数不匹配）会直接导致 metadata / timeout 异常，优先检查环境再看代码逻辑。

2. **分布式 ID（雪花 ID）在前端一律当字符串处理**

   - 任何 64 位 Long ID 只要暴露给前端，都应该在后端序列化为字符串；
   - 前端统一按 string 存储和传递，不做数值运算，避免 JS Number 精度坑。

3. **异步链路要有足够的日志与监控**

   - 每一个关键步骤都增加清晰的日志：
     - 缓存 Redis 成功 / 失败；
     - 发送 Kafka 的 topic / partition / key / messageId；
     - Kafka 消费持久化的开始 / 成功 / 异常；
     - 撤回事件发送与消费；
     - Redis 状态更新情况；
   - 方便在问题发生时，快速沿着 `messageId` 完整地追踪整条链路状态。

通过以上修复与优化，目前单聊和群聊的 **发送、异步持久化、撤回** 逻辑已经统一并稳定运行。
