# 消息模块架构亮点总结

> 面向“项目亮点 / 技术难点”视角整理，方便写简历、做分享或代码评审时使用。

---

## 1. Kafka + Redis 的异步持久化与撤回设计

### 1.1 单聊 & 群聊统一的异步链路

- **发送路径**：
  1. 生成 **雪花 ID**（Long 类型，全局唯一）。
  2. 将消息写入 Redis：`msg:detail:{messageId}`。
  3. 写入 Redis 会话列表（见下文）：
     - 单聊：`msg:conv:{min(u1,u2)}_{max(u1,u2)}`
     - 群聊：`msg:conv:{groupId}`
  4. 发送 Kafka 消息到 `im-message-private`，按会话维度分区，保证会话内顺序：
     - 单聊：分区键为 `conversationId = min(u1,u2)_max(u1,u2)`
     - 群聊：分区键为 `conversationId = groupId`
  5. Kafka 消费端落库 MySQL，并根据撤回标记更新状态。

- **撤回路径**：
  - 撤回请求到达后：
    1. 先从 Redis `msg:detail:{messageId}` 取消息，不存在则查 DB。
    2. 校验发送者 / 状态 / 5 分钟时限。
    3. 根据持久化状态：
       - `PENDING`：在 Redis 打 `msg:cancel:{messageId}` 撤回标记；
       - `PERSISTED`：发送 Kafka `RECALL` 事件，消费者更新 DB `status=0, recall_time`。
    4. 更新 Redis 详情 + 会话列表中的对应消息（单聊 & 群聊）。

**亮点**：
- 单聊 / 群聊共用同一套 **异步持久化 + 撤回协议**，减少分支逻辑；
- 利用 Kafka 的分区能力，做到 **按会话有序**，而不是按用户有序；
- 撤回通过 Redis 标记 + Kafka 事件组合，在 PENDING/PERSISTED 两种状态间完整覆盖。

---

## 2. 会话级 Redis 列表缓存（单聊 & 群聊）

### 2.1 会话列表结构设计

- 单聊会话 ID：`min(user1,user2)_max(user1,user2)`  → key: `msg:conv:{u1_u2}`。
- 群聊会话 ID：`groupId`  → key: `msg:conv:{groupId}`。
- 类型：Redis List，左插（最新在前），只保留最近 N 条（默认 1000），并设置 TTL（默认 30 分钟）。

### 2.2 使用场景

- **发送消息时写入**：
  - 单聊和群聊消息都会写入对应的会话 List。
- **撤回时更新**：
  - 找到 List 中对应 `messageId` 的元素，替换为撤回后的消息 JSON，保证历史列表与详情一致。
- **历史消息查询**：
  - `page == 1`：
    - 先从 Redis 会话 List 取最近若干条并过滤掉已删除消息；
    - 不足 `size` 再用 MySQL 补齐，并按 `sendTime` 再排序去重；
  - `page > 1`：直接使用 MySQL 分页结果，避免 Redis+DB 混合导致分页不直观。

**亮点**：
- 同时兼顾了 **首屏加载速度**（Redis 命中）和 **分页正确性**（后续页只走 DB）。
- 单聊 & 群聊共享同一套会话缓存机制，代码结构清晰。

---

## 3. PENDING 消息补偿任务优化

### 3.1 原方案问题

- 补偿任务通过：
  
  ```java
  keys("msg:detail:*")
  ```
  
  扫描 Redis 全部消息详情，然后逐条过滤 `PENDING` + 超时；
- 在消息量大时，`keys` 是阻塞命令，存在性能隐患，不适合生产环境。

### 3.2 新方案：基于 ZSet 的 PENDING 索引

引入专门的 ZSet：

- Key：`msg:pending`
- Member：`messageId`（字符串）
- Score：消息发送时间毫秒（`sendTime.toEpochMilli()`）

#### 写入索引

在 `cacheAndSendToKafka` 中：

```java
long sendTimeMillis = message.getSendTime() != null
    ? message.getSendTime().atZone(ZoneId.systemDefault()).toInstant().toEpochMilli()
    : System.currentTimeMillis();
redisTemplate.opsForZSet().add(PENDING_MESSAGE_ZSET_KEY, messageId, sendTimeMillis);
```

#### 消费端清理索引

在 Kafka 消费 `PERSIST` 事件时：

- 检测到以下几种情况时，从 `msg:pending` 中移除该 `messageId`：
  - 消息已撤回（写入前发现撤回标记）；
  - DB 已存在该记录（幂等场景）；
  - 成功持久化并更新了 Redis 状态。

#### 补偿任务按时间扫描 ZSet

- 每分钟执行：

```java
long now = System.currentTimeMillis();
long threshold = now - 5 * 60 * 1000; // 超过5分钟未持久化需要补偿
Set<String> pendingIds = redisTemplate.opsForZSet()
    .rangeByScore(PENDING_MESSAGE_ZSET_KEY, 0, threshold);
```

- 对每个 `messageId`：
  - 从 `msg:detail:{messageId}` 取详情：
    - 不存在 → 已处理，直接从 ZSet 移除；
  - 若 `persistStatus != PENDING`：说明状态已更新，移出 ZSet；
  - 若 DB 中已存在：更新 Redis 状态为 `PERSISTED` 并移出 ZSet；
  - 若有撤回标记：删除 Redis 详情并移出 ZSet；
  - 否则视为“真正需要补偿”的消息，重新发送 Kafka `PERSIST` 事件。

**亮点**：

- 从 **全库 keys 扫描** 优化为 **面向 PENDING 消息的专用索引扫描**；
- 复杂度从 O(所有消息数) 降到 O(PENDING 消息数)，对高并发场景更友好；
- 业务逻辑保持不变，只是换了更合理的数据结构和访问路径。

---

## 4. Long ID 精度问题的前后端一体化处理

虽然此部分更多是“坑点修复”，但也可以作为亮点写进文档：

- 问题：
  - 雪花 Long ID 超过 JS Number 的安全整数范围，前端解析后产生微小误差，例如：
    - 发送时：`518039478749761536`
    - 撤回时传上来：`518039478749761540`
  - 导致后端按 messageId 查 Redis / MySQL 均查不到，返回 `404 消息不存在`。

- 解决方案：
  1. 后端统一使用 Jackson 将 Long ID 序列化为 **字符串**（包括 `Message.id`、WebSocket ACK 的 `messageId`、通知 DTO 等）。
  2. 前端所有 `id` / `messageId` 字段一律按字符串处理和比较，不再依赖 JS Number。
  3. 撤回接口仍然使用 `messageId: string` 传参，Spring MVC 自动转换为 Long。

**亮点**：

- 显式解决了“分布式 ID + JS 前端”的常见坑点；
- 通过约束类型（string）而不是写注释，保证前后端行为一致。

---

## 5. 综合价值

- **一致性**：
  - 单聊 / 群聊 在发送、持久化、历史查询、撤回上走统一的异步链路和缓存策略。
- **性能**：
  - 历史消息首屏 Redis 加速，后续页 DB 分页，兼顾性能与正确性；
  - 补偿任务使用 ZSet 精确定位 PENDING 超时消息，避免 Redis 全库扫描。
- **可靠性**：
  - Kafka 消费端幂等处理 + Redis 锁，防止重复持久化；
  - 撤回逻辑对 PENDING/PERSISTED 两种状态都有完备处理路径。
- **工程化细节**：
  - 日志覆盖完整链路：发送、缓存、Kafka、补偿、撤回、通知；
  - 对 Long ID 精度问题做了系统性的前后端改造。

> 这几块结合在一起，就是整个消息子系统可以对外重点介绍的“架构亮点”。

---

## 6. 服务端运行期优化补充

### 6.1 历史消息与撤回展示一致性

- **保留撤回记录**  
  历史消息查询不再简单按 `status = 1` 过滤，而是只排除当前用户逻辑删除 (`message_delete`) 的消息，**保留 `status = 0` 的撤回消息**。前端根据 `status` 渲染：
  - 单聊：自己 → “你 撤回了一条消息”，对方 → “对方 撤回了一条消息”；
  - 群聊：自己 → “你 撤回了一条消息”，他人 → “{昵称} 撤回了一条消息”。

- **分页策略优化**  
  - `page = 1`：Redis 会话 List + MySQL 合并，保证首屏快速且完整；
  - `page > 1`：直接使用 MySQL 分页，避免 Redis + DB 混合导致多页语义复杂。

### 6.2 日志级别与噪音控制

- **控制器层保留 INFO**  
  `MessageController` / `ConversationController` 保留请求入口日志（获取历史、撤回、标记已读、清空未读、删除会话等），方便线上问题按“谁调了哪个接口”快速回溯。

- **Service 层降噪**  
  将大量高频的普通流程日志（如 `getHistoryMessages` 的命中数、`标记已读成功`、`清空未读数成功` 等）从 `INFO` 降为 `DEBUG`，只保留：
  - 关键业务结果（发送成功、撤回成功、删除会话成功）为 `INFO`；
  - 异常场景为 `WARN/ERROR`。  
  这样在默认 `INFO` 日志级别下输出更干净，需要深入排查时再打开 `DEBUG` 即可。

### 6.3 Kafka 消费并发与可观测性

- **并发消费配置**  
  在 `spring.kafka.listener` 下配置 `concurrency = 3`，结合 Topic 的 10 个分区，实现多线程消费；保持 `ack-mode = manual` 不变，继续由业务代码显式确认偏移。

- **消费链路日志增强**  
  在 `MessageKafkaConsumer.consumeMessage` 中为每条消息增加一条 `DEBUG` 日志：
  
  ```text
  topic, partition, offset, key, value
  ```
  
  出问题时可以通过 partition + offset 精确追踪某条消息的完整生命周期。

### 6.4 会话列表逻辑抽取（可维护性）

- 将单聊 / 群聊在 Redis 会话 List 中的**新增**和**撤回更新**逻辑，抽取为私有方法：
  - `appendToConversationList(Message message)`
  - `updateRecalledInConversationList(Message cachedMsg)`

- 好处：
  - 单聊 / 群聊使用统一的会话缓存更新路径，减少重复代码；
  - 后续若要调整 List 结构（例如改为只缓存最近 500 条，或增加额外字段），只需修改这两个方法即可生效于所有场景。
